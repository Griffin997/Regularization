{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a71c9a0-e2e4-4097-8c7b-00e9ae44ac52",
   "metadata": {},
   "source": [
    "# Code Description\n",
    "This code contains many functions for testing regularization methods across parameter sets and noise realizations\n",
    "\n",
    "Functions use a standard indexing to refer to our 4 parameters: 0 index is c1, 1 is c2, 2 is T21, and 3 is T22\n",
    "Regularization is applied through use of scipy.optimize.curve_fit in the estimate_parameters function\n",
    "\n",
    "Application of NLLS and regularization across parameters and noise realization can be seen below\n",
    "\n",
    "Deep neural network (DNN) regularization models are generated using the Neural Network Regularization file\n",
    "\n",
    "In general, you will be adjusting SNR below and changing the parameter sets under \"Use prior distributions of c1, c2, T21, and T22, then evaluating how effective our different estimation methods are\n",
    "\n",
    "Numerical method to calculate biased CRLB is currently under progress, so work with Dr. Balan to get that sorted\n",
    "\n",
    "This code was primarily written by Ryan Neff (RN) and then furthur developed by Griffin Hampton (GSH)\n",
    "\n",
    "This is the code that is intended to be used during the manuscript that RN is writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10825879-d5bd-4518-aacc-7cb6bb05b719",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c497587-fadd-4c07-a58d-2a2e7b07ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "import h5py\n",
    "import scipy\n",
    "import scipy.io\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import least_squares\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from tqdm import trange\n",
    "from keras.models import load_model\n",
    "from datetime import date\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de66d5",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecc152d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_opt = False\n",
    "minMSE_opt = False\n",
    "GCV_opt = True\n",
    "load_fig2 = False\n",
    "\n",
    "figure1_opt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13eafc1-2088-4b7f-ab2d-c46672cf820c",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6abc6fd2-c1c1-4a97-88ce-e04fa4850d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 100\n",
    "n_elements = 128\n",
    "c1 = 0.5\n",
    "c2 = 1 - c1\n",
    "T21 = 50\n",
    "T22 = 100\n",
    "#Weighting term to ensure the c_i and T2_i are roughly the same magnitude\n",
    "ob_weight = 100\n",
    "Nth = 5\n",
    "n_noise_realizations = 500 #500\n",
    "\n",
    "num_multistarts = 10\n",
    "\n",
    "upper_bound = [2,2,500,1500] #Set upper bound on parameters c1, c2, T21, T22, respectively\n",
    "initial = (0.5, 0.5, 250, 750) #Set initial guesses\n",
    "\n",
    "tdata = np.linspace(0, 635, n_elements)\n",
    "lambdas = np.append(0, np.logspace(-7,3,51))\n",
    "\n",
    "explore_corners = False\n",
    "\n",
    "###################### Parameters Loop Through\n",
    "c1_set = [0.5]#[0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\n",
    "c2_set = 1-np.array(c1_set)\n",
    "T21_set = [10,50]#[10,20,30,40,50]\n",
    "T22_set = [70,150]#[70,90,110,130,150]\n",
    "\n",
    "##################### Important for Naming\n",
    "date = date.today()\n",
    "day = date.strftime('%d')\n",
    "month = date.strftime('%B')[0:3]\n",
    "year = date.strftime('%y')\n",
    "\n",
    "##################### Stored Dictionary\n",
    "runInfo = {\n",
    "    \"SNR\": SNR,\n",
    "    \"c1\": c1_set,\n",
    "    \"c2\": c2_set,\n",
    "    \"T21\": T21_set,\n",
    "    \"T22\": T22_set,\n",
    "    'lambdas': lambdas,\n",
    "    'times': tdata,\n",
    "    'noise_realizations': n_noise_realizations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1a4dd-d5c4-4dd5-a7ce-eca4abf0c5d4",
   "metadata": {},
   "source": [
    "# Define General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc70ee46-56a5-40b2-bce8-8babbe4c6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Simple Functions ##############################\n",
    "# Two parameter definition of s(t) with regularization parameter lambda\n",
    "def G(t, con_1, con_2, tau_1, tau_2): \n",
    "    function = con_1*np.exp(-t/tau_1) + con_2*np.exp(-t/tau_2)\n",
    "    return function\n",
    "\n",
    "def G_tilde(lam, SA = 1):\n",
    "    #SA defines the signal amplitude, defaults to 1 for simulated data\n",
    "    def Gt_lam(t, con1, con2, tau1, tau2):\n",
    "        return np.append(G(t, con1, con2, tau1, tau2), [lam*con1/SA, lam*con2/SA, lam*tau1/ob_weight, lam*tau2/ob_weight])\n",
    "    return Gt_lam\n",
    "\n",
    "def G_tilde_linear(T21, T22, lam):\n",
    "    def G_linear(t, c1, c2):\n",
    "        return np.append(G(t, c1, c2, T21, T22), [lam*c1, lam*c2])\n",
    "    return G_linear\n",
    "\n",
    "def add_noise(signal, SNR):\n",
    "    #Given a noiseless signal, adds noise at given SNR and returns a noisy signal\n",
    "    signal_length = len(signal)\n",
    "    noise_sd = signal[0]/SNR\n",
    "    noisy_signal = signal + np.random.normal(0, noise_sd, signal_length)\n",
    "    return noisy_signal\n",
    "\n",
    "########################### Parameter Estimation Functions ########################\n",
    "\n",
    "def estimate_parameters(data, lam, n_initials = num_multistarts, post_normalize = True):\n",
    "    #Pick n_initials random initial conditions within the bound, and choose the one giving the lowest model-data mismatch residual\n",
    "    random_residuals = []\n",
    "    estimates = np.zeros((4,n_initials))\n",
    "    for i in range(n_initials):\n",
    "        ic1 = np.random.uniform(0,1)\n",
    "        ic2 = 1-ic1\n",
    "        iT21 = np.random.uniform(0,upper_bound[2])\n",
    "        iT22 = np.random.uniform(0,upper_bound[3])\n",
    "        p0 = [ic1,ic2,iT21,iT22]\n",
    "        \n",
    "        data_tilde = np.append(data, [0,0,0,0])  \n",
    "    \n",
    "        (c1e, c2e, T21e, T22e), cov = curve_fit(G_tilde(lam), tdata, data_tilde, bounds = (0, upper_bound), p0=p0, max_nfev = 4000)\n",
    "        \n",
    "        #Require T22>T21\n",
    "        if T22e > T21e:\n",
    "            estimates[:,i] = [c1e, c2e, T21e, T22e]\n",
    "            estimated_model = G(tdata, c1e, c2e, T21e, T22e)\n",
    "        else:\n",
    "            estimates[:,i] = [c2e, c1e, T22e, T21e]\n",
    "            estimated_model = G(tdata, c2e, c1e, T22e, T21e)\n",
    "        \n",
    "        residual = np.sum((estimated_model - data)**2)\n",
    "        random_residuals.append(residual)\n",
    "    min_residual_idx = np.argmin(random_residuals)\n",
    "    min_residual_estimates = estimates[:,min_residual_idx]\n",
    "\n",
    "    if post_normalize:\n",
    "        ci_sum = min_residual_estimates[0] + min_residual_estimates[1]\n",
    "        min_residual_estimates[0] = min_residual_estimates[0]/ci_sum\n",
    "        min_residual_estimates[1] = min_residual_estimates[1]/ci_sum\n",
    "\n",
    "        \n",
    "    return min_residual_estimates\n",
    "\n",
    "\n",
    "### Unused as of 11/2/22\n",
    "def min_bias_estimates(c1, c2, T21, T22, n=100, lambdas = np.logspace(-7,3, 51), aggregate=True, agg_arr = [1,1,0.01,0.01]):\n",
    "    #Returns aggregate bias, variance, and MSE of the estimates generated \n",
    "    #from using the lambda which minimizes bias for each noise realization\n",
    "    agg_arr = np.array(agg_arr)\n",
    "    noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "    \n",
    "    bias = np.zeros(4)\n",
    "    variance = np.zeros(4)\n",
    "    MSE = np.zeros(4)\n",
    "    \n",
    "    min_bias_lambdas = []\n",
    "    min_bias_est = []\n",
    "    for i in range(n):\n",
    "        np.random.seed(i)\n",
    "        data = add_noise(noiseless_curve, SNR)\n",
    "        agg_bias_list = []\n",
    "        temp_estimates = []\n",
    "        for l in range(len(lambdas)):\n",
    "            lam = lambdas[l]\n",
    "            est = estimate_parameters(data, lam)\n",
    "            temp_estimates.append(est)\n",
    "            agg_bias_list.append(np.absolute(est-[c1,c2,T21,T22]).dot(agg_arr)) #L1 error\n",
    "        \n",
    "        min_bias_idx = np.argmin(agg_bias_list)\n",
    "        \n",
    "        min_bias_lambdas.append(lambdas[min_bias_idx])\n",
    "        min_bias_est.append(temp_estimates[min_bias_idx])\n",
    "    \n",
    "    min_bias_est = np.array(min_bias_est)\n",
    "    \n",
    "    c1est = min_bias_est[:,0]\n",
    "    c2est = min_bias_est[:,1]\n",
    "    T21est = min_bias_est[:,2]\n",
    "    T22est = min_bias_est[:,3]\n",
    "    \n",
    "    bias[0] = (c1est - [c1]*n).sum()/n #GSH - check this - why are we multiplying by n - does this do something to the size - what about broadcasting?\n",
    "    bias[1] = (c2est - [c2]*n).sum()/n\n",
    "    bias[2] = (T21est - [T21]*n).sum()/n\n",
    "    bias[3] = (T22est - [T22]*n).sum()/n\n",
    "    \n",
    "    variance[0] = np.var(c1est)\n",
    "    variance[1] = np.var(c2est)\n",
    "    variance[2] = np.var(T21est)\n",
    "    variance[3] = np.var(T22est)\n",
    "    \n",
    "    MSE = bias**2 + variance\n",
    "    \n",
    "    agg_bias = np.absolute(bias).dot(agg_arr)\n",
    "    agg_variance = variance.dot(agg_arr**2)\n",
    "    agg_MSE = MSE.dot(agg_arr**2)\n",
    "    \n",
    "    if aggregate==True:\n",
    "        return agg_bias, agg_variance, agg_MSE, min_bias_lambdas\n",
    "    else:\n",
    "        return bias, variance, MSE, min_bias_lambdas\n",
    "\n",
    "def J(t, con1, con2, tau1, tau2):\n",
    "    func1 = np.exp(-t/tau1)\n",
    "    func2 = np.exp(-t/tau2)\n",
    "    func3 = (con1*t)*np.exp(-t/tau1)/(tau1**2)\n",
    "    func4 = (con2*t)*np.exp(-t/tau2)/(tau2**2)\n",
    "    jacobian = np.stack((func1, func2, func3, func4), axis=-1)\n",
    "    \n",
    "    return jacobian\n",
    "\n",
    "def cov_matrix(con1, con2, tau1, tau2, SNR):\n",
    "    noise_sd = 1/SNR\n",
    "    jacobians = J(tdata, con1, con2, tau1, tau2).transpose()@J(tdata, con1, con2, tau1, tau2) \n",
    "    covariance = np.linalg.inv(jacobians)\n",
    "    return (noise_sd**2)*covariance\n",
    "\n",
    "def get_min_MSE_array(c1_set, c2_set, T21_set, T22_set, lambdas, nReps = n_noise_realizations, verbose=False):\n",
    "    #Given a prior set of true parameters and a parameter of interest, \n",
    "    #find lambdas which give lowest MSE for each combination of parameters\n",
    "    n_c1 = len(c1_set)\n",
    "    n_c2 = len(c2_set)\n",
    "    n_T21 = len(T21_set)\n",
    "    n_T22 = len(T22_set)\n",
    "    n_params = n_c1*n_c2*n_T21*n_T22\n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    min_MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    unreg_MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    improvement_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    min_lambda_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    iterator = 1\n",
    "    start_time = time.time()\n",
    "    for ic1 in range(n_c1):\n",
    "        c1 = c1_set[ic1]\n",
    "        for ic2 in range(n_c2):\n",
    "            c2 = c2_set[ic2]\n",
    "            for iT21 in range(n_T21):\n",
    "                T21 = T21_set[iT21]\n",
    "                for iT22 in range(n_T22):\n",
    "                    T22 = T22_set[iT22]\n",
    "                    if verbose:\n",
    "                        print(f'Calculating combo {iterator} of {n_params}: {np.round(iterator/n_params*100,2)}%: ' +  \n",
    "                                f'Projected time left {(time.time()-start_time)/iterator*(n_params-iterator)/60}min')\n",
    "                        iterator+=1\n",
    "                    p_true = [c1, c2, T21, T22]\n",
    "                    noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "                    estimates = np.zeros((nReps,n_lambdas,4))\n",
    "                    for i in trange(nReps):\n",
    "                        for l in range(n_lambdas):\n",
    "                            data = add_noise(noiseless_curve, SNR)\n",
    "                            est = estimate_parameters(data, lam=lambdas[l])\n",
    "                            estimates[i,l,:] = est\n",
    "                    \n",
    "                    bias = (estimates - p_true).sum(axis=0)/nReps\n",
    "                    assert(np.allclose(np.mean(estimates - p_true, axis = 0),bias))\n",
    "                    variance = np.var(estimates, axis=0)\n",
    "                    MSE = variance + bias**2\n",
    "                    \n",
    "                    min_MSE = np.min(MSE, axis=0)\n",
    "                    min_MSE_array[ic1,ic2,iT21,iT22,:] = min_MSE\n",
    "                    \n",
    "                    unreg_MSE = MSE[0,:]\n",
    "                    unreg_MSE_array[ic1,ic2,iT21,iT22,:] = unreg_MSE\n",
    "                    \n",
    "                    improvement = (unreg_MSE - min_MSE)/unreg_MSE\n",
    "                    improvement_array[ic1,ic2,iT21,iT22,:] = improvement\n",
    "                    \n",
    "                    min_MSE_lambda_indx = np.argmin(MSE,axis=0)\n",
    "                    min_MSE_lambdas = lambdas[min_MSE_lambda_indx]\n",
    "                    min_lambda_array[ic1,ic2,iT21,iT22,:] = min_MSE_lambdas\n",
    "                    \n",
    "    return min_MSE_array, min_lambda_array, improvement_array, unreg_MSE_array\n",
    "\n",
    "def get_lam_selection_MSE_array(c1_set, c2_set, T21_set, T22_set, lambdas, lam_select, \n",
    "                                noise_iterations=n_noise_realizations, verbose=False, aggregate=False, safety_factor=2, model = None):\n",
    "    #Lam_select is either 'oracle', 'DP', 'GCV', or 'DNN'\n",
    "    #Defines which method is used to select lambda\n",
    "    n_c1 = len(c1_set)\n",
    "    n_c2 = len(c2_set)\n",
    "    n_T21 = len(T21_set)\n",
    "    n_T22 = len(T22_set)\n",
    "    n_params = n_c1*n_c2*n_T21*n_T22\n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    imp_bias_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    imp_var_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    unreg_MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    improvement_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    lambda_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    iterator = 1\n",
    "    print(\"Starting lam selection with \" + lam_select)\n",
    "    start_time = time.time()\n",
    "    for ic1 in range(n_c1):\n",
    "        c1 = c1_set[ic1]\n",
    "        c2 = 1 - c1\n",
    "        for ic2 in range(1):\n",
    "            for iT21 in range(n_T21):\n",
    "                T21 = T21_set[iT21]\n",
    "                for iT22 in range(n_T22):\n",
    "                    T22 = T22_set[iT22]\n",
    "                    if verbose:\n",
    "                        print(f'{lam_select}: Calculating combo {iterator} of {n_params}: {np.round(iterator/n_params*100,2)}%: ' +  \n",
    "                                f'Projected time left {(time.time()-start_time)/iterator*(n_params-iterator)/60}min')\n",
    "                        iterator+=1\n",
    "                    p_true = [c1, c2, T21, T22]\n",
    "                    noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "                    estimates = np.zeros((noise_iterations,4))\n",
    "                    estimates_unreg = np.zeros((noise_iterations,4))\n",
    "                    for i in trange(noise_iterations):\n",
    "                        data = add_noise(noiseless_curve, SNR)\n",
    "                        if lam_select == 'oracle':\n",
    "                            lam = oracle_lambda(c1, c2, T21, T22, data, lambdas, aggregate=aggregate)[1]\n",
    "                        elif lam_select == 'DP':\n",
    "                            lam = DP_lambda(data, safety_factor, lambdas)\n",
    "                        elif lam_select == 'GCV':\n",
    "                            try:\n",
    "                                lam = GCV_lambda(data, lambdas)\n",
    "                            except:\n",
    "                                lam=0\n",
    "                        elif lam_select == 'DNN':\n",
    "                            lam = DNN_lambda(data, model)\n",
    "                        lambda_array[ic1,ic2,iT21,iT22,:] = lam\n",
    "                        est = estimate_parameters(data, lam)\n",
    "                        est_unreg = estimate_parameters(data, 0)\n",
    "                        estimates[i,:] = est\n",
    "                        estimates_unreg[i,:] = est_unreg\n",
    "                    \n",
    "                    bias = (estimates - p_true).sum(axis=0)/noise_iterations\n",
    "                    variance = np.var(estimates, axis=0)\n",
    "                    MSE = variance + bias**2\n",
    "                    MSE_array[ic1,ic2,iT21,iT22,:] = MSE\n",
    "                    \n",
    "                    unreg_bias = (estimates_unreg - p_true).sum(axis=0)/noise_iterations\n",
    "                    unreg_variance = np.var(estimates_unreg, axis=0)\n",
    "                    unreg_MSE = unreg_variance + unreg_bias**2\n",
    "                    unreg_MSE_array[ic1,ic2,iT21,iT22,:] = unreg_MSE\n",
    "                    \n",
    "                    improvement = (unreg_MSE - MSE)/unreg_MSE\n",
    "                    improvement_array[ic1,ic2,iT21,iT22,:] = improvement\n",
    "\n",
    "                    imp_bias_array[ic1,ic2,iT21,iT22,:] = (unreg_bias - bias)/unreg_bias\n",
    "                    imp_var_array[ic1,ic2,iT21,iT22,:] = (unreg_variance - variance)/unreg_variance\n",
    "                    \n",
    "    return MSE_array, lambda_array, improvement_array, imp_bias_array, imp_var_array\n",
    "\n",
    "################## Lambda Selection Methods ########################\n",
    "\n",
    "def DP_lambda(data, safety_factor, disclambdas, fSNR = SNR):\n",
    "    #Returns a value of lambda given the data set, a safety factor, the SD of the noise, and a set of lambdas to iterate over\n",
    "    discrepancy_lambda = 0\n",
    "    noise_sd = data[0]/fSNR\n",
    "    error_norm = len(tdata)*(noise_sd)**2\n",
    "    residual_norm = []\n",
    "    for lam in disclambdas:\n",
    "        est = estimate_parameters(data,lam)\n",
    "\n",
    "        residual_norm.append(((G(tdata, est[0], est[1], est[2], est[3])-data)**2).sum())\n",
    "        \n",
    "        for i in range(len(residual_norm)):\n",
    "            if residual_norm[i] < safety_factor*error_norm:\n",
    "                discrepancy_lambda = disclambdas[i]\n",
    "            else:\n",
    "                break\n",
    "    return discrepancy_lambda\n",
    "\n",
    "def oracle_lambda(c1, c2, T21, T22, data, lambdas, aggregate=False, wgt = np.array([1,1,1/ob_weight,1/ob_weight])):\n",
    "    n_lambdas = len(lambdas)\n",
    "    estimates = np.zeros((n_lambdas,4))\n",
    "    p_true = [c1, c2, T21, T22]\n",
    "    for l in range(n_lambdas):\n",
    "        lam = lambdas[l]\n",
    "        estimates[l,:] = estimate_parameters(data, lam)\n",
    "    error = np.absolute(estimates - p_true)\n",
    "    \n",
    "    if aggregate == True:\n",
    "        #If aggregating, returns the estimates which minimize the weighted sum of the error along with a single lambda\n",
    "        agg_error = np.sum((error*wgt)**2, axis = 1) #error@wgt - L2 vs L1 error\n",
    "        assert(np.size(agg_error) == np.size(lambdas))\n",
    "        min_agg_idx = np.argmin(agg_error)\n",
    "        min_agg_est = estimates[min_agg_idx,:]\n",
    "        min_lambda = lambdas[min_agg_idx]\n",
    "        return min_agg_est, min_lambda\n",
    "    if aggregate == False:\n",
    "        #If not aggregating, returns the estimates for each parameter which minimize their respective errors\n",
    "        #Also returns 4 lambdas, one for each of the 4 parameters\n",
    "        min_idx_array = np.argmin(error,axis=0)\n",
    "        min_est_array = estimates[min_idx_array,:]\n",
    "        min_lambdas_array = lambdas[min_idx_array]\n",
    "        return min_est_array, min_lambdas_array\n",
    "\n",
    "def get_GCV(GCV_data, GCV_lam):\n",
    "    GCVd_tilde = np.append(GCV_data, [0,0,0,0])\n",
    "\n",
    "    (rc1e, rc2e, rT21e, rT22e), rcov = curve_fit(G_tilde(GCV_lam), tdata, GCVd_tilde, bounds = (0, upper_bound), p0=initial, max_nfev = 4000)\n",
    "    \n",
    "    #Require that T22>T21\n",
    "    if rT22e > rT21e:\n",
    "        c1GCV = rc1e\n",
    "        c2GCV = rc2e\n",
    "        T21GCV = rT21e\n",
    "        T22GCV = rT22e\n",
    "    else:\n",
    "        c1GCV = rc2e\n",
    "        c2GCV = rc1e\n",
    "        T21GCV = rT22e\n",
    "        T22GCV = rT21e\n",
    "    wmat = np.array([[1,0,0,0],[0,1,0,0],[0,0,0.01,0],[0,0,0,0.01]])\n",
    "    \n",
    "    GCVjacobian = J(tdata, c1GCV, c2GCV, T21GCV, T22GCV)\n",
    "    GCV_residual = ((G(tdata, c1GCV, c2GCV, T21GCV, T22GCV)-GCV_data)**2).sum()\n",
    "    C_GCV = GCVjacobian@np.linalg.inv(GCVjacobian.transpose()@GCVjacobian+(GCV_lam**2)*wmat.transpose()@wmat)@GCVjacobian.transpose()\n",
    "    (n,n) = C_GCV.shape\n",
    "    identity = np.identity(n)\n",
    "\n",
    "    GCVdenominator = (identity - C_GCV).trace()\n",
    "\n",
    "    GCV = GCV_residual/(GCVdenominator**2)\n",
    "    return GCV\n",
    "\n",
    "def GCV_lambda(GCV_data, GCVlambdas, give_curve=False):\n",
    "    #Given a data set and a set of lambdas to iterate through, gives the lambda which minimizes the GCV equation\n",
    "    GCV_values = []\n",
    "    for GCVlam in GCVlambdas:\n",
    "        GCV_values.append(get_GCV(GCV_data, GCVlam))\n",
    "    min_GCV_lam = GCVlambdas[np.argmin(GCV_values)]\n",
    "    if give_curve:\n",
    "        return min_GCV_lam, GCV_values\n",
    "    else:\n",
    "        return min_GCV_lam\n",
    "\n",
    "def DNN_lambda(data, model):\n",
    "    data_dim = np.reshape(data, (1, len(data)))\n",
    "    DNN_lam = 10**(model(data_dim))\n",
    "    return DNN_lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a95f3b-4026-4c78-a2bb-a96280fea05f",
   "metadata": {},
   "source": [
    "# Define Weighted Regularization Functions - Generating MSE vs. Lambda Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf6b855c-6a68-4608-acd5-f8ce76a5aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_regularization(n_params, param_values, param_distr, lambdas, datasets):\n",
    "    n_c1 = n_params[0]\n",
    "    n_c2 = n_params[1]\n",
    "    n_T21 = n_params[2]\n",
    "    n_T22 = n_params[3]\n",
    "    \n",
    "    c1_values = param_values[0]\n",
    "    c2_values = param_values[1]\n",
    "    T21_values = param_values[2]\n",
    "    T22_values = param_values[3]\n",
    "    \n",
    "    c1_distribution = param_distr[0]\n",
    "    c2_distribution = param_distr[1]\n",
    "    T21_distribution = param_distr[2]\n",
    "    T22_distribution = param_distr[3]\n",
    "    \n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    weighted_bias = 0\n",
    "    weighted_variance = 0\n",
    "    weighted_MSE = 0\n",
    "    \n",
    "    iterator = 1\n",
    "    total_combos = n_c1 * n_c2 * n_T21 * n_T22\n",
    "    for nc1 in range(n_c1):\n",
    "        for nc2 in range(n_c2):\n",
    "            for nt1 in range(n_T21):\n",
    "                for nt2 in range(n_T22):\n",
    "                    print(f'Calculating combo {iterator} of {total_combos}')\n",
    "                \n",
    "                    con1 = c1_values[nc1]\n",
    "                    con2 = c2_values[nc2]\n",
    "                    tau1 = T21_values[nt1]\n",
    "                    tau2 = T22_values[nt2]\n",
    "                    p_true = [con1, con2, tau1, tau2]\n",
    "                    weight = c1_distribution[nc1]*c2_distribution[nc2]*T21_distribution[nt1]*T22_distribution[nt2]\n",
    "                    \n",
    "                    estimates = np.zeros((n_noise_realizations,n_lambdas,4))\n",
    "                    for i in trange(n_noise_realizations):\n",
    "                        data = datasets[nc1,nc2,nt1,nt2,i,:]\n",
    "                        for l in range(n_lambdas):\n",
    "                            lam = lambdas[l]\n",
    "                            est = estimate_parameters(data, lam)\n",
    "                            estimates[i,l] = est\n",
    "                    \n",
    "                    bias = (estimates - p_true).sum(axis=0)/n_noise_realizations\n",
    "                    variance = np.var(estimates, axis=0)\n",
    "                    MSE = variance + bias**2\n",
    "                    \n",
    "                    weighted_bias += weight*bias\n",
    "                    weighted_variance += weight*variance\n",
    "                    weighted_MSE += weight*MSE\n",
    "    return weighted_bias, weighted_variance, weighted_MSE\n",
    "\n",
    "def weighted_GCV_reg(n_params, param_values, param_distr, lambdas, datasets):\n",
    "    n_c1 = n_params[0]\n",
    "    n_c2 = n_params[1]\n",
    "    n_T21 = n_params[2]\n",
    "    n_T22 = n_params[3]\n",
    "    \n",
    "    c1_values = param_values[0]\n",
    "    c2_values = param_values[1]\n",
    "    T21_values = param_values[2]\n",
    "    T22_values = param_values[3]\n",
    "    \n",
    "    c1_distribution = param_distr[0]\n",
    "    c2_distribution = param_distr[1]\n",
    "    T21_distribution = param_distr[2]\n",
    "    T22_distribution = param_distr[3]\n",
    "    \n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    weighted_bias = 0\n",
    "    weighted_variance = 0\n",
    "    weighted_MSE = 0\n",
    "    \n",
    "    GCV_lambda_list = []\n",
    "    iterator = 1\n",
    "    total_combos = n_c1 * n_c2 * n_T21 * n_T22\n",
    "    for nc1 in range(n_c1):\n",
    "        for nc2 in range(n_c2):\n",
    "            for nt1 in range(n_T21):\n",
    "                for nt2 in range(n_T22):\n",
    "                    print(f'Calculating combo {iterator} of {total_combos}')\n",
    "                \n",
    "                    con1 = c1_values[nc1]\n",
    "                    con2 = c2_values[nc2]\n",
    "                    tau1 = T21_values[nt1]\n",
    "                    tau2 = T22_values[nt2]\n",
    "                    p_true = [con1, con2, tau1, tau2]\n",
    "                    weight = c1_distribution[nc1]*c2_distribution[nc2]*T21_distribution[nt1]*T22_distribution[nt2]\n",
    "                    \n",
    "                    GCV_estimates = []\n",
    "                    for i in trange(n_noise_realizations):\n",
    "                        data = datasets[nc1,nc2,nt1,nt2,i,:]\n",
    "                        lam = GCV_lambda(data, lambdas)\n",
    "                        GCV_lambda_list.append(lam)\n",
    "    \n",
    "                        GCVEst = estimate_parameters(data, lam)\n",
    "                        GCV_estimates.append(GCVEst)\n",
    "\n",
    "                    GCV_estimates = np.array(GCV_estimates)\n",
    "                    \n",
    "                    GCV_bias = (GCV_estimates - p_true).sum(axis=0)/n_noise_realizations\n",
    "                    GCV_variance = np.var(GCV_estimates, axis=0)\n",
    "                    GCV_MSE = GCV_variance + GCV_bias**2\n",
    "                    \n",
    "                    weighted_bias += weight*GCV_bias\n",
    "                    weighted_variance += weight*GCV_variance\n",
    "                    weighted_MSE += weight*GCV_MSE\n",
    "    return weighted_bias, weighted_variance, weighted_MSE, GCV_lambda_list\n",
    "\n",
    "def weighted_DNN_reg(model, n_params, param_values, param_distr, datasets):\n",
    "    #Tests the DNN over a range of true parameter values, returns the weighted bias, variance, and MSE of the DNN estimates\n",
    "    n_c1 = n_params[0]\n",
    "    n_c2 = n_params[1]\n",
    "    n_T21 = n_params[2]\n",
    "    n_T22 = n_params[3]\n",
    "    \n",
    "    c1_values = param_values[0]\n",
    "    c2_values = param_values[1]\n",
    "    T21_values = param_values[2]\n",
    "    T22_values = param_values[3]\n",
    "    \n",
    "    c1_distribution = param_distr[0]\n",
    "    c2_distribution = param_distr[1]\n",
    "    T21_distribution = param_distr[2]\n",
    "    T22_distribution = param_distr[3]\n",
    "    \n",
    "    weighted_bias = 0\n",
    "    weighted_variance = 0\n",
    "    weighted_MSE = 0\n",
    "    \n",
    "    total_DNN_lambdas = []\n",
    "\n",
    "    iterator = 1\n",
    "    total_combos = n_c1 * n_c2 * n_T21 * n_T22\n",
    "    for nc1 in range(n_c1):\n",
    "        for nc2 in range(n_c2):\n",
    "            for nt1 in range(n_T21):\n",
    "                for nt2 in range(n_T22):\n",
    "                    print(f'Calculating combo {iterator} of {total_combos}')\n",
    "                \n",
    "                    con1 = c1_values[nc1]\n",
    "                    con2 = c2_values[nc2]\n",
    "                    tau1 = T21_values[nt1]\n",
    "                    tau2 = T22_values[nt2]\n",
    "                    p_true = [con1, con2, tau1, tau2]\n",
    "                \n",
    "                    weight = c1_distribution[nc1]*c2_distribution[nc2]*T21_distribution[nt1]*T22_distribution[nt2]\n",
    "                    underlying = G(tdata, con1, con2, tau1, tau2)\n",
    "                    param_datasets = datasets[nc1,nc2,nt1,nt2,:,:]\n",
    "                    DNN_lambdas = np.array(model(param_datasets))\n",
    "            \n",
    "                    DNN_estimates = []\n",
    "                    for i in range(n_noise_realizations):\n",
    "                        data = param_datasets[i,:]\n",
    "                        lam = 10**DNN_lambdas[i]\n",
    "                        total_DNN_lambdas.append(lam)\n",
    "    \n",
    "                        DNNEst = estimate_parameters(data, lam)\n",
    "                        DNN_estimates.append(DNNEst)\n",
    "\n",
    "                    DNN_estimates = np.array(DNN_estimates)\n",
    "                    \n",
    "                    DNN_bias = (DNN_estimates - p_true).sum(axis=0)/n_noise_realizations\n",
    "                    DNN_variance = np.var(DNN_estimates, axis=0)\n",
    "                    DNN_MSE = DNN_variance + DNN_bias**2\n",
    "                    \n",
    "                    weighted_bias += weight*DNN_bias\n",
    "                    weighted_variance += weight*DNN_variance\n",
    "                    weighted_MSE += weight*DNN_MSE\n",
    "    return weighted_bias, weighted_variance, weighted_MSE, total_DNN_lambdas\n",
    "\n",
    "def weighted_oracle_reg(n_params, param_values, param_distr, lambdas, datasets):\n",
    "    n_c1 = n_params[0]\n",
    "    n_c2 = n_params[1]\n",
    "    n_T21 = n_params[2]\n",
    "    n_T22 = n_params[3]\n",
    "    \n",
    "    c1_values = param_values[0]\n",
    "    c2_values = param_values[1]\n",
    "    T21_values = param_values[2]\n",
    "    T22_values = param_values[3]\n",
    "    \n",
    "    c1_distribution = param_distr[0]\n",
    "    c2_distribution = param_distr[1]\n",
    "    T21_distribution = param_distr[2]\n",
    "    T22_distribution = param_distr[3]\n",
    "    \n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    weighted_bias = 0\n",
    "    weighted_variance = 0\n",
    "    weighted_MSE = 0\n",
    "    \n",
    "    oracle_lambda_list = []\n",
    "    iterator = 1\n",
    "    total_combos = n_c1 * n_c2 * n_T21 * n_T22\n",
    "    for nc1 in range(n_c1):\n",
    "        for nc2 in range(n_c2):\n",
    "            for nt1 in range(n_T21):\n",
    "                for nt2 in range(n_T22):\n",
    "                    print(f'Calculating combo {iterator} of {total_combos}')\n",
    "                \n",
    "                    con1 = c1_values[nc1]\n",
    "                    con2 = c2_values[nc2]\n",
    "                    tau1 = T21_values[nt1]\n",
    "                    tau2 = T22_values[nt2]\n",
    "                    p_true = [con1, con2, tau1, tau2]\n",
    "                    weight = c1_distribution[nc1]*c2_distribution[nc2]*T21_distribution[nt1]*T22_distribution[nt2]\n",
    "                    \n",
    "                    oracle_estimates = []\n",
    "                    for i in trange(n_noise_realizations):\n",
    "                        data = datasets[nc1,nc2,nt1,nt2,i,:]\n",
    "                        oraEst, lam = oracle_lambda(con1, con2, tau1, tau2, data, lambdas, aggregate=True)\n",
    "                        oracle_lambda_list.append(lam)\n",
    "                        oracle_estimates.append(np.array(oraEst))\n",
    "\n",
    "                    oracle_estimates = np.array(oracle_estimates)\n",
    "                    \n",
    "                    ora_bias = (oracle_estimates - p_true).sum(axis=0)/n_noise_realizations\n",
    "                    #Why not just use the mean?\n",
    "                    ora_variance = np.var(oracle_estimates, axis=0)\n",
    "                    ora_MSE = ora_variance + ora_bias**2\n",
    "                    \n",
    "                    weighted_bias += weight*ora_bias\n",
    "                    weighted_variance += weight*ora_variance\n",
    "                    weighted_MSE += weight*ora_MSE\n",
    "    return weighted_bias, weighted_variance, weighted_MSE, oracle_lambda_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed95543-a709-434f-a6ac-7cee1a9c203f",
   "metadata": {},
   "source": [
    "# Generate Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39009d18-b751-4a07-ad81-58bee078711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 38566.18it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = np.zeros((n_noise_realizations, n_elements))\n",
    "noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "for n in trange(n_noise_realizations):\n",
    "    np.random.seed(n)\n",
    "    data = add_noise(noiseless_curve, SNR)\n",
    "    datasets[n,:] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7920228-1ea3-4ff6-965b-23cffe8af34c",
   "metadata": {},
   "source": [
    "# Use prior distributions of c1, c2, T21, and T22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c4660d-59f2-4397-a1db-0281da7815cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.65it/s]\n"
     ]
    }
   ],
   "source": [
    "#General idea is to define sets of parameters and test regularization methods across those parameters, \n",
    "#then do a weighted average to see how performance is affected by choice of parameter set\n",
    "#Weighting array to ensure parameters are roughly the same magnitude\n",
    "wgt = np.array([1,1,0.01,0.01])\n",
    "#Number of values in each parameter set, index 0 refers to c1, 1 to c2, 2 to T21, and 3 to T22\n",
    "n_params = [1,1,1,1]\n",
    "n_total_params = n_params[0]*n_params[1]*n_params[2]*n_params[3]\n",
    "\n",
    "n_lambdas = 51 #Number of lambdas to loop through\n",
    "lambdas = np.logspace(-7, 3, n_lambdas) #Set range of lambda values\n",
    "#Defines sets for each parameter using np.linspace\n",
    "c1_values = np.linspace(0.5,0.5, n_params[0])\n",
    "c2_values = np.linspace(0.5,0.5, n_params[1])\n",
    "T21_values = np.linspace(40, 40, n_params[2])\n",
    "T22_values = np.linspace(130, 130, n_params[3])\n",
    "#Parametrized version of above, done to save some space\n",
    "param_values = [c1_values, c2_values, T21_values, T22_values]\n",
    "#Define weighted distributions of the parameters, here just weights each value equally\n",
    "c1_distribution = np.array([1]*n_params[0])\n",
    "c1_distribution = c1_distribution/c1_distribution.sum()\n",
    "c2_distribution = np.array([1]*n_params[1])\n",
    "c2_distribution = c2_distribution/c2_distribution.sum()\n",
    "T21_distribution = np.array([1]*n_params[2])\n",
    "T21_distribution = T21_distribution/T21_distribution.sum()\n",
    "T22_distribution = np.array([1]*n_params[3])\n",
    "T22_distribution = T22_distribution/T22_distribution.sum()\n",
    "#Parametrized distributions to save some space\n",
    "param_distr = [c1_distribution, c2_distribution, T21_distribution, T22_distribution]\n",
    "\n",
    "param_averages = [value@distr for value, distr in zip(param_values, param_distr)]\n",
    "\n",
    "#Generate the data sets and calculate the weighted CRLB over the parameter distribution\n",
    "#Pregenerating the data sets saves some computation time later\n",
    "datasets_distr = np.zeros((n_params[0],n_params[1],n_params[2],n_params[3],n_noise_realizations,n_elements))\n",
    "weighted_CRLB = 0\n",
    "for nc1 in trange(n_params[0]):\n",
    "    for nc2 in range(n_params[1]):\n",
    "        for nt1 in range(n_params[2]):\n",
    "            for nt2 in range(n_params[3]):\n",
    "                \n",
    "                con1 = c1_values[nc1]\n",
    "                #con2 = c2_values[nc2]\n",
    "                con2 = 1-con1\n",
    "                tau1 = T21_values[nt1]\n",
    "                tau2 = T22_values[nt2]\n",
    "                \n",
    "                cov = cov_matrix(con1, con2, tau1, tau2, SNR)\n",
    "                weighted_CRLB += np.array([cov[0,0],cov[1,1],cov[2,2],cov[3,3]])/n_total_params  \n",
    "                p_true = [con1, con2, tau1, tau2]\n",
    "                \n",
    "                underlying = G(tdata, con1, con2, tau1, tau2)\n",
    "                datasets = []\n",
    "                for i in range(n_noise_realizations):\n",
    "                    np.random.seed(i)\n",
    "                    data = add_noise(noiseless_curve, SNR)\n",
    "                    datasets_distr[nc1,nc2,nt1,nt2,i,:] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8abd6564-f44b-4bd7-a6dd-8c51ac60314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if figure1_opt:\n",
    "    #Test the different methods over the parameter distributions\n",
    "    start_time1 = time.time()\n",
    "    weighted_min_bias, weighted_min_variance, weighted_min_MSE, min_lambdas = weighted_oracle_reg(\n",
    "        n_params, param_values, param_distr, lambdas, datasets_distr)\n",
    "    print('Oracle runtime:', time.time() - start_time1, 'seconds')\n",
    "\n",
    "    start_time2 = time.time()\n",
    "    bias_weighted, variance_weighted, MSE_weighted = weighted_regularization(\n",
    "        n_params, param_values, param_distr, lambdas, datasets_distr)\n",
    "    print('NLLS runtime:', time.time() - start_time2, 'seconds')\n",
    "\n",
    "    start_time3 = time.time()\n",
    "    weighted_GCV_bias, weighted_GCV_variance, weighted_GCV_MSE, GCV_lambdas = weighted_GCV_reg(\n",
    "        n_params, param_values, param_distr, lambdas, datasets_distr)\n",
    "    print('GCV runtime:', time.time() - start_time3, 'seconds')\n",
    "    start_time4 = time.time()\n",
    "    # model = load_model('DNN Networks//reg_model SNR 100 3-23.h5')\n",
    "    # weighted_DNN_bias, weighted_DNN_variance, weighted_DNN_MSE, DNN_lambdas = weighted_DNN_reg(\n",
    "        # model, n_params, param_values, param_distr,datasets_distr)\n",
    "    # print('DNN runtime:', time.time() - start_time4, 'seconds')\n",
    "\n",
    "    print('SNR:', SNR)\n",
    "    print('Weighted CRLB:', weighted_CRLB)\n",
    "    print('Weighted uMSE:', MSE_weighted[0,:])\n",
    "    print('Weighted GCV MSE:', weighted_GCV_MSE)\n",
    "    # print('Weighted DNN MSE:', weighted_DNN_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f7ee914-f610-4c26-bda6-7b5525cd3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if figure1_opt:\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (15,6), tight_layout=True)\n",
    "    fig.suptitle('Lambda selection histograms, SNR = %s'%SNR)\n",
    "    ax[0].hist(np.log10(min_lambdas), bins=20)\n",
    "    ax[1].hist(np.log10(GCV_lambdas), bins=20)\n",
    "    # ax[2].hist(np.log10(DNN_lambdas), bins=20)\n",
    "\n",
    "    ax[0].set_xlabel('log10(lambda)')\n",
    "    ax[0].set_ylabel('Counts')\n",
    "    ax[0].set_title('Optimal, minimum error lambdas')\n",
    "    ax[1].set_xlabel('log10(lambda)')\n",
    "    ax[1].set_ylabel('Counts')\n",
    "    ax[1].set_title('GCV lambdas')\n",
    "    # ax[2].set_xlabel('log10(lambda)')\n",
    "    # ax[2].set_ylabel('Counts')\n",
    "    # ax[2].set_title('Neural network lambdas')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b365bd50-2dbb-4274-a614-8b54eeb44338",
   "metadata": {},
   "outputs": [],
   "source": [
    "if figure1_opt:    \n",
    "    figure, axis = plt.subplots(2, 2, figsize=(12, 8),tight_layout=True)\n",
    "\n",
    "    figure.suptitle('Regularized Mean Square Errors vs. Conventional NLLS, SNR = %s'%SNR)\n",
    "\n",
    "    axis[0,0].set_title('c1 MSE vs. Lambda')\n",
    "    axis[0,0].loglog(lambdas, MSE_weighted[:,0], label = 'c1 MSE', color='b')\n",
    "    axis[0,0].axhline(y=MSE_weighted[0,0], label = 'c1 Unreg MSE', color='orange')\n",
    "    #axis[0,0].axhline(y=weighted_CRLB[0], label = 'c1 CRLB',color='c')\n",
    "    axis[0,0].axhline(y=weighted_GCV_MSE[0], label = 'c1 GCV MSE',color='m')\n",
    "    # axis[0,0].axhline(y=weighted_DNN_MSE[0], label = 'c1 DNN MSE', color='r')\n",
    "    axis[0,0].axhline(y=weighted_min_MSE[0], label = 'c1 oracle MSE', color='g')\n",
    "    axis[0,0].set_ylabel('Mean Square Error')\n",
    "    axis[0,0].set_xlabel('Lambda')\n",
    "    axis[0,0].legend()\n",
    "\n",
    "    axis[0,1].set_title('c2 MSE vs. Lambda')\n",
    "    axis[0,1].loglog(lambdas, MSE_weighted[:,1], label = 'c2 MSE', color='b')\n",
    "    axis[0,1].axhline(y=MSE_weighted[0,1], label = 'c2 Unreg MSE', color='orange')\n",
    "    #axis[0,1].axhline(y=weighted_CRLB[1], label = 'c2 CRLB',color='c')\n",
    "    axis[0,1].axhline(y=weighted_GCV_MSE[1], label = 'c2 GCV MSE',color='m')\n",
    "    # axis[0,1].axhline(y=weighted_DNN_MSE[1], label = 'c2 DNN MSE', color='r')\n",
    "    axis[0,1].axhline(y=weighted_min_MSE[1], label = 'c2 oracle MSE', color='g')\n",
    "    axis[0,1].set_ylabel('Mean Square Error')\n",
    "    axis[0,1].set_xlabel('Lambda')\n",
    "    axis[0,1].legend()\n",
    "\n",
    "    axis[1,0].set_title('T21 MSE vs. Lambda')\n",
    "    axis[1,0].loglog(lambdas, MSE_weighted[:,2], label = 'T21 MSE', color='b')\n",
    "    axis[1,0].axhline(y=MSE_weighted[0,2], label = 'T21 Unreg MSE', color='orange')\n",
    "    #axis[1,0].axhline(y=weighted_CRLB[2], label = 'T21 CRLB',color='c')\n",
    "    axis[1,0].axhline(y=weighted_GCV_MSE[2], label = 'T21 GCV MSE',color='m')\n",
    "    # axis[1,0].axhline(y=weighted_DNN_MSE[2], label = 'T21 DNN MSE', color='r')\n",
    "    axis[1,0].axhline(y=weighted_min_MSE[2], label = 'T21 oracle MSE', color='g')\n",
    "    axis[1,0].set_ylabel('Mean Square Error')\n",
    "    axis[1,0].set_xlabel('Lambda')\n",
    "    axis[1,0].legend()\n",
    "\n",
    "    axis[1,1].set_title('T22 MSE vs. Lambda')\n",
    "    axis[1,1].loglog(lambdas, MSE_weighted[:,3], label = 'T22 MSE', color='b')\n",
    "    axis[1,1].axhline(y=MSE_weighted[0,3], label = 'T22 Unreg MSE', color='orange')\n",
    "    #axis[1,1].axhline(y=weighted_CRLB[3], label = 'T22 CRLB',color='c')\n",
    "    axis[1,1].axhline(y=weighted_GCV_MSE[3], label = 'T22 GCV MSE',color='m')\n",
    "    # axis[1,1].axhline(y=weighted_DNN_MSE[3], label = 'T22 DNN MSE', color='r')\n",
    "    axis[1,1].axhline(y=weighted_min_MSE[3], label = 'T22 oracle MSE', color='g')\n",
    "    axis[1,1].set_ylabel('Mean Square Error')\n",
    "    axis[1,1].set_xlabel('Lambda')\n",
    "    axis[1,1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdf23457-c848-4bdf-94e9-afc83962cbe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if figure1_opt:\n",
    "    figure, axis = plt.subplots(3, 4, figsize=(30, 12.8),tight_layout=True)\n",
    "\n",
    "    plabels = ['c1','c2','T21','T22']\n",
    "\n",
    "    figure.suptitle('Weighted Bias, Variance, and MSE vs Lambda, SNR = %s' % SNR)\n",
    "    for p in range(4):\n",
    "        axis[0,p].semilogx(lambdas, bias_weighted[:,p], label='%s weighted bias'%plabels[p], color='b')\n",
    "        axis[0,p].axhline(y=weighted_GCV_bias[p], label = '%s GCV Bias'%plabels[p], color='m')\n",
    "        # axis[0,p].axhline(y=weighted_DNN_bias[p], label = '%s DNN Bias'%plabels[p], color='r')\n",
    "        axis[0,p].set_ylabel('%s weighted bias'%plabels[p])\n",
    "        \n",
    "        axis[1,p].semilogx(lambdas, variance_weighted[:,p], label='%s weighted variance'%plabels[p], color='b')\n",
    "        axis[1,p].axhline(y=weighted_GCV_variance[p], label = '%s GCV Variance'%plabels[p], color='m')\n",
    "        # axis[1,p].axhline(y=weighted_DNN_variance[p], label = '%s DNN Variance'%plabels[p], color='r')\n",
    "        axis[1,p].set_ylabel('%s weighted variance'%plabels[p])\n",
    "        \n",
    "        axis[2,p].loglog(lambdas, MSE_weighted[:,p], label='%s weighted MSE'%plabels[p], color='b')\n",
    "        #axis[2,p].axhline(y=param_CRLB[p], label = '%s weighted CRLB'%plabels[p])\n",
    "        axis[2,p].axhline(y=weighted_GCV_MSE[p], label='%s weighted GCV MSE'%plabels[p], color='m')\n",
    "        # axis[2,p].axhline(y=weighted_DNN_MSE[p], label='%s weighted DNN MSE'%plabels[p], color='r')\n",
    "        axis[2,p].set_ylabel('%s weighted CoV'%plabels[p])\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "            axis[i,j].legend()\n",
    "            axis[i,j].set_xlabel('Lambda')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea75f5-61b6-4d30-a742-400f64ec82e4",
   "metadata": {},
   "source": [
    "### Show an aggregate measure of bias, variance, and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88d06cee-3322-4738-8a3e-abe1a59314a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if figure1_opt:\n",
    "    aggregate_bias = np.absolute(bias_weighted).dot(wgt)\n",
    "    aggregate_variance = np.array(variance_weighted).dot(wgt**2)\n",
    "    aggregate_MSE = np.array(MSE_weighted).dot(wgt**2)\n",
    "    aggregate_CoV = (np.sqrt(MSE_weighted)/param_averages).sum(axis=-1)/4\n",
    "\n",
    "    agg_GCV_bias = np.absolute(weighted_GCV_bias).dot(wgt)\n",
    "    agg_GCV_variance = weighted_GCV_variance.dot(wgt**2)\n",
    "    agg_GCV_MSE = weighted_GCV_MSE.dot(wgt**2)\n",
    "    agg_GCV_CoV = (np.sqrt(weighted_GCV_MSE)/param_averages).sum()/4\n",
    "\n",
    "    # agg_DNN_bias = np.absolute(weighted_DNN_bias).dot(wgt)\n",
    "    # agg_DNN_variance = np.array(weighted_DNN_variance).dot(wgt**2)\n",
    "    # agg_DNN_MSE = np.array(weighted_DNN_MSE).dot(wgt**2)\n",
    "    # agg_DNN_CoV = (np.sqrt(weighted_DNN_MSE)/param_averages).sum()/4\n",
    "\n",
    "    agg_min_bias = np.absolute(weighted_min_bias).dot(wgt)\n",
    "    agg_min_variance = np.array(weighted_min_variance).dot(wgt**2)\n",
    "    agg_min_MSE = np.array(weighted_min_MSE).dot(wgt**2)\n",
    "    agg_min_CoV = (np.sqrt(weighted_min_MSE)/param_averages).sum()/4\n",
    "\n",
    "    #agg_DNN_pdf_bias = np.absolute(DNN_pdf_bias).dot(wgt)\n",
    "    #agg_DNN_pdf_variance = np.array(DNN_pdf_variance).dot(wgt**2)\n",
    "    #agg_DNN_pdf_MSE = np.array(DNN_pdf_MSE).dot(wgt**2)\n",
    "    #agg_DNN_pdf_CoV = (np.sqrt(DNN_pdf_MSE)/param_averages).dot(wgt)\n",
    "\n",
    "    #agg_CRLB = np.array(param_CRLB).dot(wgt**2)\n",
    "    #agg_CRLB_adjusted = (np.sqrt(param_CRLB)/param_averages).dot(wgt)\n",
    "\n",
    "    fig, ax = plt.subplots(3,1,figsize=(8,12), tight_layout=True)\n",
    "    fig.suptitle('Aggregate measures vs Lambda, SNR = %s' % SNR)\n",
    "    ax[0].semilogx(lambdas, aggregate_bias, label='Aggregate Bias', color='b')\n",
    "    ax[0].semilogx(lambdas, [agg_GCV_bias]*n_lambdas, label = 'Aggregate GCV Bias',color='m')\n",
    "    # ax[0].semilogx(lambdas, [agg_DNN_bias]*n_lambdas, label = 'Aggregate DNN Bias', color='r')\n",
    "    #ax[0].semilogx(lambdas, [agg_DNN_pdf_bias]*n_lambdas, label = 'Aggregate DNN PDF Bias')\n",
    "    ax[0].semilogx(lambdas, [agg_min_bias]*n_lambdas, label = 'Min tot error', color='g')\n",
    "    ax[0].set_ylabel('Bias')\n",
    "    ax[0].set_xlabel('Lambda')\n",
    "    ax[0].set_title('Aggregate Measure of Bias')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].semilogx(lambdas, aggregate_variance, label='Aggregate Variance', color='b')\n",
    "    ax[1].semilogx(lambdas, [agg_GCV_variance]*n_lambdas, label = 'Aggregate GCV Variance',color='m')\n",
    "    # ax[1].semilogx(lambdas, [agg_DNN_variance]*n_lambdas, label = 'Aggregate DNN Variance', color='r')\n",
    "    #ax[1].semilogx(lambdas, [agg_DNN_pdf_variance]*n_lambdas, label = 'Aggregate DNN PDF Variance')\n",
    "    ax[1].semilogx(lambdas, [agg_min_variance]*n_lambdas, label = 'Min tot error', color='g')\n",
    "    ax[1].set_ylabel('Variance')\n",
    "    ax[1].set_xlabel('Lambda')\n",
    "    ax[1].set_title('Aggregate Measure of Variance')\n",
    "    ax[1].legend()\n",
    "\n",
    "    ax[2].loglog(lambdas, aggregate_MSE, label='Aggregate MSE', color='b')\n",
    "    ax[2].loglog(lambdas, [agg_GCV_MSE]*n_lambdas, label = 'Aggregate GCV MSE',color='m')\n",
    "    # ax[2].loglog(lambdas, [agg_DNN_MSE]*n_lambdas, label = 'Aggregate DNN MSE', color='r')\n",
    "    #ax[2].loglog(lambdas, [agg_DNN_pdf_MSE]*n_lambdas, label = 'Aggregate DNN PDF CoV')\n",
    "    #ax[2].loglog(lambdas, [agg_CRLB_adjusted]*n_lambdas, label = 'Aggregate adjusted CRLB')\n",
    "    ax[2].loglog(lambdas, [agg_min_MSE]*n_lambdas, label = 'Min tot error', color='g')\n",
    "    ax[2].set_ylabel('MSE')\n",
    "    ax[2].set_xlabel('Lambda')\n",
    "    ax[2].set_title('Aggregate Measure of MSE')\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d466a-1c47-4386-bd3d-de1f02d0faa1",
   "metadata": {},
   "source": [
    "# Show improvement over a range of T21 and T22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d8a08b1-e1f4-4e8b-b63c-6503bb49525a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting lam selection with GCV\n",
      "GCV: Calculating combo 1 of 4: 25.0%: Projected time left 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [07:14<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCV: Calculating combo 2 of 4: 50.0%: Projected time left 7.235053996245067min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [08:27<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCV: Calculating combo 3 of 4: 75.0%: Projected time left 5.233718914455838min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [14:53<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCV: Calculating combo 4 of 4: 100.0%: Projected time left 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [07:41<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCV time: 38.27251055240631  minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if load_fig2:\n",
    "    if minMSE_opt:\n",
    "        print('TODO')\n",
    "\n",
    "    if oracle_opt:\n",
    "        print('TODO')\n",
    "\n",
    "    if GCV_opt:\n",
    "        with h5py.File(f'SimulationSets//GCV//fig2set_100_10Nov22.hdf5','a') as f:\n",
    "            #Save a data set\n",
    "            # dset = f.create_dataset('runInfo',data=runInfo)\n",
    "            GCV_MSE_array = np.array(f['MSE_array'])\n",
    "            GCV_lambda_array = np.array(f['lambda_array'])\n",
    "            GCV_imp_array = np.array(f['improvement_array'])\n",
    "        with open('SimulationSets//GCV//runInfo_100_10Nov22.pkl', 'rb') as handle:\n",
    "            dict = pickle.load(handle)\n",
    "        SNR = dict['SNR']\n",
    "\n",
    "    \n",
    "else:\n",
    "    if minMSE_opt:\n",
    "        start_time = time.time()\n",
    "        min_MSE_array, min_lambda_array, min_MSE_imp_array, unreg_MSE_array = get_min_MSE_array(\n",
    "            c1_set, c2_set, T21_set, T22_set, lambdas, verbose=False)\n",
    "        print('Min MSE time:', (time.time()-start_time)/60, ' minutes')\n",
    "\n",
    "    if oracle_opt:\n",
    "        start_time = time.time()\n",
    "        oracle_MSE_array, oracle_lambda_array, oracle_imp_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set, T22_set, lambdas, 'oracle', aggregate=True)\n",
    "        print('Oracle time:', (time.time()-start_time)/60, ' minutes')\n",
    "\n",
    "    if GCV_opt:\n",
    "        start_time = time.time()\n",
    "        GCV_MSE_array, GCV_lambda_array, GCV_imp_array, GCV_imp_bias_array, GCV_imp_var_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set, T22_set, lambdas, 'GCV', verbose = True)\n",
    "        print('GCV time:', (time.time()-start_time)/60, ' minutes')\n",
    "\n",
    "\n",
    "# model = load_model('DNN Networks//reg_model SNR 100 3-23.h5')\n",
    "# DNN_MSE_array, DNN_lambda_array, DNN_imp_array = get_lam_selection_MSE_array(\n",
    "    # c1_set, c2_set, T21_set, T22_set, lambdas, 'DNN', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75f90303-f05e-409b-bb4b-148874699c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if oracle_opt:\n",
    "    #Parameter of interest, using the standard indexing for this code\n",
    "    POI = 0\n",
    "    fig, ax = plt.subplots(figsize = (5, 5), tight_layout=True)\n",
    "    fig.suptitle(\"Oracle Improvement over NLLS, SNR = %s\" % SNR)\n",
    "    imc1 = ax.imshow(oracle_imp_array[0,0,:,:,POI], cmap = 'Oranges', vmin = 0, vmax = 1.2)\n",
    "\n",
    "    ax.set_title('Improvement in c1 MSE')\n",
    "    ax.set_xticks(np.arange(len(T22_set)))\n",
    "    ax.set_yticks(np.arange(len(T21_set)))\n",
    "    ax.set_xticklabels(T22_set)\n",
    "    ax.set_yticklabels(T21_set)\n",
    "    ax.set_ylabel('T21 values')\n",
    "    ax.set_xlabel('T22 values')\n",
    "\n",
    "    for i in range(len(T21_set)):\n",
    "        for j in range(len(T22_set)):\n",
    "            text = ax.text(j, i, round(oracle_imp_array[0,0,i,j,0], 3), ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    with h5py.File(f'SimulationSets//oracle//fig2set_{SNR}_' + day + month + year +'.hdf5','a') as f:\n",
    "        #Save a data set\n",
    "        dset = f.create_dataset('runInfo',data=runInfo)\n",
    "        dset = f.create_dataset('MSE_array',data=oracle_MSE_array)\n",
    "        dset = f.create_dataset('lambda_array',data=oracle_lambda_array)\n",
    "        dset = f.create_dataset('improvement_array',data=oracle_imp_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2cedf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "if minMSE_opt:\n",
    "    #Parameter of interest, using the standard indexing for this code\n",
    "    POI = 0\n",
    "    fig, ax = plt.subplots(figsize = (5, 5), tight_layout=True)\n",
    "    fig.suptitle(\"min MSE Improvement over NLLS, SNR = %s\" % SNR)\n",
    "    imc1 = ax.imshow(min_MSE_imp_array[0,0,:,:,POI], cmap = 'Oranges', vmin = 0, vmax = 1.2)\n",
    "\n",
    "    ax.set_title('Improvement in c1 MSE')\n",
    "    ax.set_xticks(np.arange(len(T22_set)))\n",
    "    ax.set_yticks(np.arange(len(T21_set)))\n",
    "    ax.set_xticklabels(T22_set)\n",
    "    ax.set_yticklabels(T21_set)\n",
    "    ax.set_ylabel('T21 values')\n",
    "    ax.set_xlabel('T22 values')\n",
    "\n",
    "    for i in range(len(T21_set)):\n",
    "        for j in range(len(T22_set)):\n",
    "            text = ax.text(j, i, round(min_MSE_imp_array[0,0,i,j,0], 3), ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    with h5py.File(f'SimulationSets//minMSE//fig2set_{SNR}_' + day + month + year +'.hdf5','a') as f:\n",
    "        #Save a data set\n",
    "        dset = f.create_dataset('runInfo',data=runInfo)\n",
    "        dset = f.create_dataset('MSE_array',data=min_MSE_array)\n",
    "        dset = f.create_dataset('lambda_array',data=min_lambda_array)\n",
    "        dset = f.create_dataset('improvement_array',data=min_MSE_imp_array)\n",
    "        dset = f.create_dataset('unreg_MSE_array',data=unreg_MSE_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "296a0088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [47], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m         text \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mtext(j, i, MSE_summary, ha\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m\"\u001b[39m, va\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m\"\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39mFile(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSimulationSets//GCV//fig2set_\u001b[39m\u001b[39m{\u001b[39;00mSNR\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m day \u001b[39m+\u001b[39m month \u001b[39m+\u001b[39m year \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.hdf5\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     22\u001b[0m     \u001b[39m#Save a data set\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[39m# dset = f.create_dataset('runInfo',data=runInfo)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     dset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mcreate_dataset(\u001b[39m'\u001b[39;49m\u001b[39mMSE_array\u001b[39;49m\u001b[39m'\u001b[39;49m,data\u001b[39m=\u001b[39;49mGCV_MSE_array)\n\u001b[0;32m     25\u001b[0m     dset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mcreate_dataset(\u001b[39m'\u001b[39m\u001b[39mlambda_array\u001b[39m\u001b[39m'\u001b[39m,data\u001b[39m=\u001b[39mGCV_lambda_array)\n\u001b[0;32m     26\u001b[0m     dset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mcreate_dataset(\u001b[39m'\u001b[39m\u001b[39mimprovement_array\u001b[39m\u001b[39m'\u001b[39m,data\u001b[39m=\u001b[39mGCV_imp_array)\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\h5py\\_hl\\group.py:161\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    158\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    159\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 161\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    162\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\h5py\\_hl\\dataset.py:156\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     sid \u001b[39m=\u001b[39m h5s\u001b[39m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 156\u001b[0m dset_id \u001b[39m=\u001b[39m h5d\u001b[39m.\u001b[39;49mcreate(parent\u001b[39m.\u001b[39;49mid, name, tid, sid, dcpl\u001b[39m=\u001b[39;49mdcpl, dapl\u001b[39m=\u001b[39;49mdapl)\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m (data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    159\u001b[0m     dset_id\u001b[39m.\u001b[39mwrite(h5s\u001b[39m.\u001b[39mALL, h5s\u001b[39m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if GCV_opt:\n",
    "    #Parameter of interest, using the standard indexing for this code\n",
    "    POI = 0\n",
    "    fig, ax = plt.subplots(figsize = (5, 5), tight_layout=True)\n",
    "    fig.suptitle(\"GCV Improvement over NLLS, SNR = %s\" % SNR)\n",
    "    imc1 = ax.imshow(GCV_imp_array[0,0,:,:,POI], cmap = 'Oranges', vmin = 0, vmax = 1.2)\n",
    "\n",
    "    ax.set_title('Improvement in c1 MSE')\n",
    "    ax.set_xticks(np.arange(len(T22_set)))\n",
    "    ax.set_yticks(np.arange(len(T21_set)))\n",
    "    ax.set_xticklabels(T22_set)\n",
    "    ax.set_yticklabels(T21_set)\n",
    "    ax.set_ylabel('T21 values')\n",
    "    ax.set_xlabel('T22 values')\n",
    "\n",
    "    for i in range(len(T21_set)):\n",
    "        for j in range(len(T22_set)):\n",
    "            MSE_summary = (f\"{round(GCV_imp_array[0,0,i,j,0], 3)}\\n{round(GCV_imp_bias_array[0,0,i,j,0], 3)}\\n{round(GCV_imp_var_array[0,0,i,j,0], 3)}\")\n",
    "            text = ax.text(j, i, MSE_summary, ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    with h5py.File(f'SimulationSets//GCV//fig2set_{SNR}_' + day + month + year +'.hdf5','a') as f:\n",
    "        #Save a data set\n",
    "        # dset = f.create_dataset('runInfo',data=runInfo)\n",
    "        dset = f.create_dataset('MSE_array',data=GCV_MSE_array)\n",
    "        dset = f.create_dataset('lambda_array',data=GCV_lambda_array)\n",
    "        dset = f.create_dataset('improvement_array',data=GCV_imp_array)\n",
    "        dset = f.create_dataset('bias_improvement_array',data=GCV_imp_bias_array)\n",
    "        dset = f.create_dataset('variance_improvement_array',data=GCV_imp_var_array)\n",
    "\n",
    "    f = open(f'SimulationSets//GCV//runInfo_{SNR}_' + day + month + year +'.pkl','wb')\n",
    "    pickle.dump(runInfo,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c3c784d-9811-44ae-bdf3-04ea9a61c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POI = 0\n",
    "# fig, ax = plt.subplots(2, 2, figsize = (10, 10), tight_layout=True)\n",
    "# fig.suptitle(\"DNN improvement over NLLS, SNR = %s\" % SNR)\n",
    "# imc1 = ax[0,0].imshow(DNN_imp_array[0,0,:,:,0])\n",
    "# imc2 = ax[0,1].imshow(DNN_imp_array[0,0,:,:,1])\n",
    "# imT21 = ax[1,0].imshow(DNN_imp_array[0,0,:,:,2])\n",
    "# imT22 = ax[1,1].imshow(DNN_imp_array[0,0,:,:,3])\n",
    "\n",
    "# ax[0,0].set_title('Improvement in c1 MSE')\n",
    "# ax[0,0].set_xticks(np.arange(len(T22_set)))\n",
    "# ax[0,0].set_yticks(np.arange(len(T21_set)))\n",
    "# ax[0,0].set_xticklabels(T22_set)\n",
    "# ax[0,0].set_yticklabels(T21_set)\n",
    "# ax[0,0].set_ylabel('T21 values')\n",
    "# ax[0,0].set_xlabel('T22 values')\n",
    "\n",
    "# for i in range(len(T21_set)):\n",
    "#     for j in range(len(T22_set)):\n",
    "#         text = ax[0,0].text(j, i, round(DNN_imp_array[0,0,i,j,0], 2), ha=\"center\", va=\"center\", color=\"red\")\n",
    "        \n",
    "# ax[1,0].set_title('Improvement in c2 MSE')\n",
    "# ax[1,0].set_xticks(np.arange(len(T22_set)))\n",
    "# ax[1,0].set_yticks(np.arange(len(T21_set)))\n",
    "# ax[1,0].set_xticklabels(T22_set)\n",
    "# ax[1,0].set_yticklabels(T21_set)\n",
    "# ax[1,0].set_ylabel('T21 values')\n",
    "# ax[1,0].set_xlabel('T22 values')\n",
    "\n",
    "# for i in range(len(T21_set)):\n",
    "#     for j in range(len(T22_set)):\n",
    "#         text = ax[1,0].text(j, i, round(DNN_imp_array[0,0,i,j,1], 2), ha=\"center\", va=\"center\", color=\"red\")\n",
    "        \n",
    "# ax[0,1].set_title('Improvement in T21 MSE')\n",
    "# ax[0,1].set_xticks(np.arange(len(T22_set)))\n",
    "# ax[0,1].set_yticks(np.arange(len(T21_set)))\n",
    "# ax[0,1].set_xticklabels(T22_set)\n",
    "# ax[0,1].set_yticklabels(T21_set)\n",
    "# ax[0,1].set_ylabel('T21 values')\n",
    "# ax[0,1].set_xlabel('T22 values')\n",
    "\n",
    "# for i in range(len(T21_set)):\n",
    "#     for j in range(len(T22_set)):\n",
    "#         text = ax[0,1].text(j, i, round(DNN_imp_array[0,0,i,j,2], 2), ha=\"center\", va=\"center\", color=\"red\")\n",
    "        \n",
    "# ax[1,1].set_title('Improvement in T22 MSE')\n",
    "# ax[1,1].set_xticks(np.arange(len(T22_set)))\n",
    "# ax[1,1].set_yticks(np.arange(len(T21_set)))\n",
    "# ax[1,1].set_xticklabels(T22_set)\n",
    "# ax[1,1].set_yticklabels(T21_set)\n",
    "# ax[1,1].set_ylabel('T21 values')\n",
    "# ax[1,1].set_xlabel('T22 values')\n",
    "\n",
    "# for i in range(len(T21_set)):\n",
    "#     for j in range(len(T22_set)):\n",
    "#         text = ax[1,1].text(j, i, round(DNN_imp_array[0,0,i,j,3], 2), ha=\"center\", va=\"center\", color=\"red\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d5630",
   "metadata": {},
   "source": [
    "##### Exploring the corner cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bef37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore_corners:\n",
    "\n",
    "    c1_set = [0.5]\n",
    "    c2_set = [0.5]\n",
    "    T21_set1 = [10]\n",
    "    T22_set1 = [150]\n",
    "\n",
    "    T21_set2 = [50]\n",
    "    T22_set2 = [70]\n",
    "\n",
    "    n_opt = 25\n",
    "    n_iters = np.linspace(500//n_opt,500,25)\n",
    "    iter_length = np.size(n_iters)\n",
    "\n",
    "    oracle_topRight_MSE = np.zeros((iter_length,4))\n",
    "    oracle_botLeft_MSE = np.zeros((iter_length,4))\n",
    "    GCV_topRight_MSE = np.zeros((iter_length,4))\n",
    "    GCV_botLeft_MSE = np.zeros((iter_length,4))\n",
    "\n",
    "    for i in trange(iter_length):\n",
    "\n",
    "        iter_size = n_iters[i]\n",
    "\n",
    "        oracle_MSE_array, oracle_lambda_array, oracle_imp_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set1, T22_set1, lambdas, 'oracle', aggregate=True, noise_iterations = iter_size)\n",
    "        oracle_topRight_MSE[i,:] = oracle_MSE_array[0,0,0,0,:]\n",
    "            \n",
    "        GCV_MSE_array, GCV_lambda_array, GCV_imp_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set1, T22_set1, lambdas, 'GCV', noise_iterations = iter_size)\n",
    "        GCV_topRight_MSE[i,:] =  GCV_MSE_array[0,0,0,0,:]\n",
    "\n",
    "        oracle_MSE_array, oracle_lambda_array, oracle_imp_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set2, T22_set2, lambdas, 'oracle', aggregate=True, noise_iterations = iter_size)\n",
    "        oracle_botLeft_MSE[i,:] = oracle_MSE_array[0,0,0,0,:]\n",
    "            \n",
    "        GCV_MSE_array, GCV_lambda_array, GCV_imp_array = get_lam_selection_MSE_array(\n",
    "            c1_set, c2_set, T21_set2, T22_set2, lambdas, 'GCV', noise_iterations = iter_size)\n",
    "        GCV_botLeft_MSE[i,:] =  GCV_MSE_array[0,0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a115fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore_corners:\n",
    "    save_MSE_array = False\n",
    "    load_MSE_array = False\n",
    "    n_iters = np.arange(10,501,10)\n",
    "\n",
    "    if save_MSE_array:\n",
    "        try:\n",
    "            with h5py.File('Storage//CornerCases.hdf5','a') as f:\n",
    "                #Save a data set\n",
    "                dset = f.create_dataset('oracle_topRight',data=oracle_topRight_MSE)\n",
    "                dset = f.create_dataset('oracle_botLeft',data=oracle_botLeft_MSE)\n",
    "                dset = f.create_dataset('GCV_topRight',data=GCV_topRight_MSE)\n",
    "                dset = f.create_dataset('GCV_botLeft',data=GCV_botLeft_MSE)\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "    if load_MSE_array:\n",
    "        with h5py.File('Storage//CornerCases.hdf5','a') as f:\n",
    "            oracle_topRight_MSE = np.array(f['oracle_topRight'])\n",
    "            oracle_botLeft_MSE = np.array(f['oracle_botLeft'])\n",
    "            GCV_topRight_MSE = np.array(f['GCV_topRight'])\n",
    "            GCV_botLeft_MSE = np.array(f['GCV_botLeft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5751c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if explore_corners:\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,5), tight_layout=True)\n",
    "    fig.suptitle('MSE Compared to Iteration')\n",
    "    ax[0].plot(n_iters, oracle_topRight_MSE[:,0], label= 'Oracle TopRight', alpha = 0.7)\n",
    "    ax[0].plot(n_iters, GCV_topRight_MSE[:,0], label= 'GCV TopRight', alpha = 0.7)\n",
    "    ax[1].plot(n_iters, oracle_botLeft_MSE[:,0], label= 'Oracle BotLeft', alpha = 0.7)\n",
    "    ax[1].plot(n_iters, GCV_botLeft_MSE[:,0], label= 'GCV BotLeft', alpha = 0.7)\n",
    "    ax[0].set_xlabel('Number of Iterations')\n",
    "    ax[0].set_ylabel('MSE')\n",
    "    ax[0].set_title('T21 = 10 & T22 = 150')\n",
    "    ax[1].set_xlabel('Number of Iterations')\n",
    "    ax[1].set_ylabel('MSE')\n",
    "    ax[1].set_title('T21 = 50 & T22 = 70')\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd008c-a0b6-4f28-9dae-ebd5e314bfe6",
   "metadata": {},
   "source": [
    "# Use a numerical method to calculate the biased CRLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c1041d7-fb9f-4e2e-9cf8-5db8ba29c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_P_theta_n(theta_n, c_range, T2_range, M):\n",
    "    #theta_n are the 4 parameters to perturb around, given as a numpy array\n",
    "    #c_range and T2_range are define the range of the perturbations about ci and T2i\n",
    "    #M is the number of total perturbations\n",
    "    #The first entry in P_theta_n is always just theta_n\n",
    "    P_theta_n = np.zeros((4, M+1))\n",
    "    P_theta_n[:,0] = theta_n\n",
    "    for m in range(M):\n",
    "        a1_m = np.random.uniform(low=c_range[0],high=c_range[1])\n",
    "        a2_m = np.random.uniform(low=c_range[0],high=c_range[1])\n",
    "        tau1_m = np.random.uniform(low=T2_range[0],high=T2_range[1])\n",
    "        tau2_m = np.random.uniform(low=T2_range[0],high=T2_range[1])\n",
    "        \n",
    "        T_theta_nm = np.append(a1_m, [a2_m, tau1_m, tau2_m])\n",
    "        \n",
    "        P_theta_n[:, m+1] = theta_n + T_theta_nm\n",
    "        \n",
    "    return P_theta_n\n",
    "\n",
    "def construct_A_n(P_theta_n):\n",
    "    #Gives matrix A_n for least squares minimization to get biased CRLB for parameters theta_n\n",
    "    #P_theta_n is the perturbation matrix about some theta_n\n",
    "    M = P_theta_n.shape[1]-1\n",
    "    theta_n = P_theta_n[:,0]\n",
    "    \n",
    "    #Get first four rows of A_n first\n",
    "    z = P_theta_n[:,1] - theta_n\n",
    "    B1 = [z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0,0,0]\n",
    "    B2 = [0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0,0]\n",
    "    B3 = [0,0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0]\n",
    "    B4 = [0,0,0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3]]\n",
    "    A_n = np.stack((B1, B2, B3, B4),axis=0)\n",
    "    #Then get the rest of the rows\n",
    "    for m in range(M-1):\n",
    "        z = P_theta_n[:,m+2] - theta_n\n",
    "        B1 = [z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0,0,0]\n",
    "        B2 = [0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0,0]\n",
    "        B3 = [0,0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3],0]\n",
    "        B4 = [0,0,0,z[0],0,0,0,z[1],0,0,0,z[2],0,0,0,z[3]]\n",
    "        \n",
    "        B_mn = np.stack((B1, B2, B3, B4), axis=0)\n",
    "        A_n = np.concatenate((A_n, B_mn),axis=0)\n",
    "        \n",
    "    return A_n\n",
    "\n",
    "def run_NR_P_theta_n(P_theta_n, n_noise_realizations):\n",
    "    M = P_theta_n.shape[1]\n",
    "    estimates = np.zeros((4, M, n_noise_realizations))\n",
    "    for m in range(M):\n",
    "        [c1, c2, T21, T22] = P_theta_n[:,m]\n",
    "        \n",
    "        #np.random.seed(m)\n",
    "        noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "        for i in range(n_noise_realizations):\n",
    "            noise_realization = add_noise(noiseless_curve, SNR)\n",
    "            est = estimate_parameters(noise_realization, 0)\n",
    "            estimates[:,m,i] = est\n",
    "    return estimates\n",
    "\n",
    "def x_cost_fun(bias_var_n, A_n):\n",
    "    def function(x):\n",
    "        #For giving least squares the vector of the residual\n",
    "        return (bias_var_n - A_n@x)\n",
    "    return function\n",
    "\n",
    "def biased_CRLB(theta_n, c_range, T2_range, M, n_noise_realizations):\n",
    "    #Calculates the biased CRLB about a set of parameters theta_n\n",
    "    P_theta_n = construct_P_theta_n(theta_n, c_range, T2_range, M)\n",
    "    estimates = run_NR_P_theta_n(P_theta_n, n_noise_realizations)\n",
    "    \n",
    "    sample_mean = np.mean(estimates,axis=-1)\n",
    "    Q_0 = sample_mean[:,0]\n",
    "    sample_mean_shortened = sample_mean[:,1:]\n",
    "    \n",
    "    bias_var_n = np.reshape((sample_mean_shortened.transpose() - Q_0),-1)\n",
    "    \n",
    "    A_n = construct_A_n(P_theta_n)\n",
    "    \n",
    "    minimization = x_cost_fun(bias_var_n, A_n)\n",
    "    x_hat_n = least_squares(minimization, np.zeros(16))['x']\n",
    "    \n",
    "    #x_hat_n = (np.linalg.inv(A_n.transpose()@A_n)@A_n.transpose())@bias_var_n\n",
    "    S_hat_n = np.transpose(np.reshape(x_hat_n, (4,4)))\n",
    "    CRLB_n = cov_matrix(theta_n[0],theta_n[1],theta_n[2],theta_n[3], SNR)\n",
    "\n",
    "    biased_CRLB = S_hat_n@CRLB_n@S_hat_n.transpose()\n",
    "    \n",
    "    return biased_CRLB, S_hat_n\n",
    "\n",
    "def check_CRLB_convergence(n_set, theta_n, c_range, T2_range, M, verbose=False):\n",
    "    n_checks = len(n_set)\n",
    "    P_theta_n = construct_P_theta_n(theta_n, c_range, T2_range, M)\n",
    "    CRLB_n = cov_matrix(theta_n[0],theta_n[1],theta_n[2],theta_n[3], SNR)\n",
    "    biased_CRLB_set = []\n",
    "    c1_CRLB_set = []\n",
    "    c2_CRLB_set = []\n",
    "    T21_CRLB_set = []\n",
    "    T22_CRLB_set = []\n",
    "    sensitivity_set = []\n",
    "    for i in trange(n_checks):\n",
    "        if i == 0:\n",
    "            n_noise_realizations = n_set[i]\n",
    "            estimates = run_NR_P_theta_n(P_theta_n, n_noise_realizations)\n",
    "        else:\n",
    "            n_noise_realizations = n_set[i] - n_set[i-1]\n",
    "            new_estimates = run_NR_P_theta_n(P_theta_n, n_noise_realizations)\n",
    "            estimates = np.append(estimates, new_estimates,axis=-1)\n",
    "        sample_mean = np.mean(estimates, axis=-1)\n",
    "        Q_0 = sample_mean[:,0]\n",
    "        sample_mean_shortened = sample_mean[:,1:]\n",
    "        bias_var_n = np.reshape((sample_mean_shortened.transpose() - Q_0),-1)\n",
    "        A_n = construct_A_n(P_theta_n)\n",
    "        \n",
    "        minimization = x_cost_fun(bias_var_n, A_n)\n",
    "        x_hat_n = least_squares(minimization, np.zeros(16))['x']\n",
    "        S_hat_n = np.transpose(np.reshape(x_hat_n, (4,4)))\n",
    "        sensitivity_set.append(S_hat_n)\n",
    "\n",
    "        biased_CRLB = S_hat_n@CRLB_n@(S_hat_n.transpose())\n",
    "        biased_CRLB_set.append(biased_CRLB)\n",
    "        \n",
    "        c1_CRLB = biased_CRLB[0,0]\n",
    "        c1_CRLB_set.append(c1_CRLB)\n",
    "        c2_CRLB = biased_CRLB[1,1]\n",
    "        c2_CRLB_set.append(c2_CRLB)\n",
    "        T21_CRLB = biased_CRLB[2,2]\n",
    "        T21_CRLB_set.append(T21_CRLB)\n",
    "        T22_CRLB = biased_CRLB[3,3] \n",
    "        T22_CRLB_set.append(T22_CRLB)\n",
    "        if verbose:\n",
    "            print('Biased CRLB at %s noise realizations:'%(n_set[i]), c1_CRLB, c2_CRLB, T21_CRLB, T22_CRLB)\n",
    "            \n",
    "    return biased_CRLB_set, c1_CRLB_set, c2_CRLB_set, T21_CRLB_set, T22_CRLB_set, sensitivity_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3423482f-f656-4d1b-abcd-431a0528a014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_n = np.array((0.3, 0.7, 50, 90))\n",
    "c_range = [-0.05, 0.05]\n",
    "T2_range = [-2.5, 2.5]\n",
    "M = 10\n",
    "n_noise_realizations = 100\n",
    "\n",
    "CRLB_n = cov_matrix(theta_n[0],theta_n[1],theta_n[2],theta_n[3], SNR)\n",
    "biased_CRLB_n, sensitivity = biased_CRLB(theta_n, c_range, T2_range, M, n_noise_realizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b418f8ee-92b5-4052-92ad-194c6051832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1000 [21:36<32:23:17, 117.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m M \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      6\u001b[0m n_set \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m100\u001b[39m, \u001b[39m100000\u001b[39m, \u001b[39m1000\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m biased_CRLB_set, c1_CRLB_set, c2_CRLB_set, T21_CRLB_set, T22_CRLB_set, sensitivity_set \u001b[39m=\u001b[39m check_CRLB_convergence(\n\u001b[0;32m      8\u001b[0m     n_set, theta_n, c_range, T2_range, M, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn [29], line 106\u001b[0m, in \u001b[0;36mcheck_CRLB_convergence\u001b[1;34m(n_set, theta_n, c_range, T2_range, M, verbose)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     n_noise_realizations \u001b[39m=\u001b[39m n_set[i] \u001b[39m-\u001b[39m n_set[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 106\u001b[0m     new_estimates \u001b[39m=\u001b[39m run_NR_P_theta_n(P_theta_n, n_noise_realizations)\n\u001b[0;32m    107\u001b[0m     estimates \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(estimates, new_estimates,axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    108\u001b[0m sample_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(estimates, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn [29], line 56\u001b[0m, in \u001b[0;36mrun_NR_P_theta_n\u001b[1;34m(P_theta_n, n_noise_realizations)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_noise_realizations):\n\u001b[0;32m     55\u001b[0m         noise_realization \u001b[39m=\u001b[39m add_noise(noiseless_curve, SNR)\n\u001b[1;32m---> 56\u001b[0m         est \u001b[39m=\u001b[39m estimate_parameters(noise_realization, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     57\u001b[0m         estimates[:,m,i] \u001b[39m=\u001b[39m est\n\u001b[0;32m     58\u001b[0m \u001b[39mreturn\u001b[39;00m estimates\n",
      "Cell \u001b[1;32mIn [12], line 40\u001b[0m, in \u001b[0;36mestimate_parameters\u001b[1;34m(data, lam, n_initials, post_normalize)\u001b[0m\n\u001b[0;32m     36\u001b[0m p0 \u001b[39m=\u001b[39m [ic1,ic2,iT21,iT22]\n\u001b[0;32m     38\u001b[0m data_tilde \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(data, [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m])  \n\u001b[1;32m---> 40\u001b[0m (c1e, c2e, T21e, T22e), cov \u001b[39m=\u001b[39m curve_fit(G_tilde(lam), tdata, data_tilde, bounds \u001b[39m=\u001b[39;49m (\u001b[39m0\u001b[39;49m, upper_bound), p0\u001b[39m=\u001b[39;49mp0, max_nfev \u001b[39m=\u001b[39;49m \u001b[39m4000\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m \u001b[39m#Require T22>T21\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m T22e \u001b[39m>\u001b[39m T21e:\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py:845\u001b[0m, in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, **kwargs)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmax_nfev\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    843\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mmax_nfev\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmaxfev\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 845\u001b[0m res \u001b[39m=\u001b[39m least_squares(func, p0, jac\u001b[39m=\u001b[39mjac, bounds\u001b[39m=\u001b[39mbounds, method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    846\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    848\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m res\u001b[39m.\u001b[39msuccess:\n\u001b[0;32m    849\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOptimal parameters not found: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\least_squares.py:928\u001b[0m, in \u001b[0;36mleast_squares\u001b[1;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     result \u001b[39m=\u001b[39m call_minpack(fun_wrapped, x0, jac_wrapped, ftol, xtol, gtol,\n\u001b[0;32m    925\u001b[0m                           max_nfev, x_scale, diff_step)\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 928\u001b[0m     result \u001b[39m=\u001b[39m trf(fun_wrapped, jac_wrapped, x0, f0, J0, lb, ub, ftol, xtol,\n\u001b[0;32m    929\u001b[0m                  gtol, max_nfev, x_scale, loss_function, tr_solver,\n\u001b[0;32m    930\u001b[0m                  tr_options\u001b[39m.\u001b[39;49mcopy(), verbose)\n\u001b[0;32m    932\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdogbox\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[39mif\u001b[39;00m tr_solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlsmr\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mregularize\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m tr_options:\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\trf.py:123\u001b[0m, in \u001b[0;36mtrf\u001b[1;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m trf_no_bounds(\n\u001b[0;32m    120\u001b[0m         fun, jac, x0, f0, J0, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[0;32m    121\u001b[0m         loss_function, tr_solver, tr_options, verbose)\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m trf_bounds(\n\u001b[0;32m    124\u001b[0m         fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[0;32m    125\u001b[0m         loss_function, tr_solver, tr_options, verbose)\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\trf.py:300\u001b[0m, in \u001b[0;36mtrf_bounds\u001b[1;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[0;32m    298\u001b[0m J_augmented[:m] \u001b[39m=\u001b[39m J \u001b[39m*\u001b[39m d\n\u001b[0;32m    299\u001b[0m J_h \u001b[39m=\u001b[39m J_augmented[:m]  \u001b[39m# Memory view.\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m J_augmented[m:] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdiag(diag_h\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m    301\u001b[0m U, s, V \u001b[39m=\u001b[39m svd(J_augmented, full_matrices\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    302\u001b[0m V \u001b[39m=\u001b[39m V\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mdiag\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1443\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1744\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\co\\NIA\\.grif_venv\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      6\u001b[0m _temp \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread()\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_is_stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 3.x has this\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mis_thread_alive\u001b[39m(t):\n\u001b[0;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m     12\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_Thread__stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Check for convergence\n",
    "theta_n = np.array((0.5, 0.5, 20, 200))\n",
    "c_range = [-0.05, 0.05]\n",
    "T2_range = [-2.5, 2.5]\n",
    "M = 10\n",
    "n_set = np.linspace(100, 100000, 1000, dtype=int)\n",
    "biased_CRLB_set, c1_CRLB_set, c2_CRLB_set, T21_CRLB_set, T22_CRLB_set, sensitivity_set = check_CRLB_convergence(\n",
    "    n_set, theta_n, c_range, T2_range, M, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a8e93-d5f5-4fd5-95e7-8e51ea9c70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRLB_n = cov_matrix(theta_n[0],theta_n[1],theta_n[2],theta_n[3], SNR)\n",
    "c1_CRLB = CRLB_n[0,0]\n",
    "c2_CRLB = CRLB_n[1,1]\n",
    "T21_CRLB = CRLB_n[2,2]\n",
    "T22_CRLB = CRLB_n[3,3]\n",
    "fig, ax = plt.subplots(1,4,figsize=(18,4),tight_layout=True)\n",
    "fig.suptitle('Convergence of biased CRLB at SNR %s'%SNR)\n",
    "ax[0].plot(n_set, c1_CRLB_set, label='c1 biased CRLB')\n",
    "ax[0].axhline(y=c1_CRLB, label = 'c1 CRLB', color='r')\n",
    "ax[0].set_xlabel('Noise realizations')\n",
    "ax[0].set_ylabel('CRLB')\n",
    "ax[0].set_title('c1 convergence')\n",
    "ax[0].legend()\n",
    "ax[1].plot(n_set, c2_CRLB_set, label='c2 biased CRLB')\n",
    "ax[1].axhline(y=c2_CRLB, label = 'c2 CRLB', color='r')\n",
    "ax[1].set_xlabel('Noise realizations')\n",
    "ax[1].set_ylabel('CRLB')\n",
    "ax[1].set_title('c2 convergence')\n",
    "ax[1].legend()\n",
    "ax[2].plot(n_set, T21_CRLB_set, label='T21 biased CRLB')\n",
    "ax[2].axhline(y=T21_CRLB, label = 'T21 CRLB', color='r')\n",
    "ax[2].set_xlabel('Noise realizations')\n",
    "ax[2].set_ylabel('CRLB')\n",
    "ax[2].set_title('T21 convergence')\n",
    "ax[2].legend()\n",
    "ax[3].plot(n_set, T22_CRLB_set, label='T22 biased CRLB')\n",
    "ax[3].axhline(y=T22_CRLB, label = 'T22 CRLB', color='r')\n",
    "ax[3].set_xlabel('Noise realizations')\n",
    "ax[3].set_ylabel('CRLB')\n",
    "ax[3].set_title('T22 convergence')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923597c-9e2a-4059-be1a-2b1ad03e124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('Brain MWF Maps//Biased CRLB SNR 1 Convergence, 1e5 NR 5-22.hdf5','a') as f2:\n",
    "#     f2.create_dataset('biased CRLB', data=biased_CRLB_set)\n",
    "#     f2.create_dataset('sensitivity', data=sensitivity_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f9461e57c8aaeccb5a4202f3eb0df437b94cded3914cf93be397abab25dc6de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
